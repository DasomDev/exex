<!DOCTYPE html><html lang="ko"><head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>오픈소스 기반 데이터 분석: 기말고사 대비 문제</title>
  <link href="https://us-tiangong-data.oss-accelerate.aliyuncs.com/doc/gemini_css/writing_blue.css?OSSAccessKeyId=LTAI5tGmBYBVtG6Cxb4BaviJ&amp;Expires=4914044167&amp;Signature=LiIovJR%2Foq6fZUmsFbgoH9wTm6M%3D" rel="stylesheet"/>
  <link href="https://us-tiangong-data.oss-accelerate.aliyuncs.com/doc/gemini_css/table.css?OSSAccessKeyId=LTAI5tGmBYBVtG6Cxb4BaviJ&amp;Expires=4914044665&amp;Signature=X%2F%2BipJztge3UJ3Ojq5wcxRk%2F7zk%3D" rel="stylesheet"/>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.css" rel="stylesheet"/>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="https://us-tiangong-data.oss-accelerate.aliyuncs.com/doc/gemini_css/macarons_v2.js?OSSAccessKeyId=LTAI5tGmBYBVtG6Cxb4BaviJ&amp;Expires=4914188330&amp;Signature=mE%2FFv6owOnvs%2FB7rWTRxwD9tj9M%3D"></script>
  
  </head>
  <body>
  <div class="container">
  <header>
  <h1 id="section-1">오픈소스 기반 데이터 분석</h1>
  <p>기말고사 대비 종합 문제</p>
  </header>
  <div class="update-time">
              현재 시간: 2025-10-27
          </div>
  <h2 class="section-title" id="section-1">I. 정형 데이터 분석 (Structured Data Analysis)</h2>
  <div class="question-block">
  <p class="question-text">1. 정형 데이터의 특징으로 가장 거리가 <u>먼</u> 것은 무엇입니까?</p>
  <ol>
  <li>행과 열로 구성된 명확한 구조를 가진다.</li>
  <li>데이터베이스, 스프레드시트, CSV 파일 형태로 주로 존재한다.</li>
  <li>이미지, 음성, 텍스트 등 다양한 형태로 존재하며 분석이 어렵다.</li>
  <li>구조화된 형태로 인해 집계, 필터링, 정렬 등 기본적 처리가 용이하다.</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p>정형 데이터는 이름에서 알 수 있듯이 &#39;정해진 형식&#39;을 가진 데이터를 의미합니다. 주어진 자료에 따르면 정형 데이터는 다음과 같은 특징을 가집니다.</p>
  <ul>
  <li><strong>명확한 구조:</strong> 행(Row)과 열(Column)으로 구성된 테이블 형태의 구조를 가집니다. 각 열은 특정 속성(Attribute)을, 각 행은 개별 레코드(Record)나 개체(Entity)를 나타냅니다. (1번 설명)</li>
  <li><strong>저장 형태:</strong> 이러한 구조 덕분에 관계형 데이터베이스(RDBMS), 엑셀과 같은 스프레드시트, CSV(Comma-Separated Values) 파일 형식으로 저장 및 관리되는 것이 일반적입니다. (2번 설명)</li>
  <li><strong>분석 용이성:</strong> 구조가 명확하기 때문에 집계(Aggregation), 필터링(Filtering), 정렬(Sorting)과 같은 기본적인 데이터 처리 작업이 용이하며, 이를 바탕으로 고급 통계 분석까지 다양한 분석 기법을 쉽게 적용할 수 있습니다. 이는 분석 결과의 신뢰성과 해석 용이성을 높이는 장점으로 이어집니다. (4번 설명)</li>
  </ul>
  <p>반면, 3번에서 설명하는 &#39;이미지, 영상, 음성, 텍스트 등 다양한 형태로 존재하며 분석이 어려운&#39; 데이터는 <strong>비정형 데이터(Unstructured Data)</strong>의 특징입니다. 비정형 데이터는 일정한 형식이나 구조가 없어 전통적인 분석 방법으로는 처리하기 어렵지만, 풍부한 정보를 담고 있어 딥러닝과 같은 최신 기술을 통해 가치를 창출할 수 있습니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">2. Pandas 라이브러리를 사용하여 두 개의 DataFrame(<code>daily_usage_df</code>, <code>rain_df</code>)을 결합하고자 합니다. &#39;기준_날짜&#39;와 &#39;일시&#39;를 기준으로, <code>daily_usage_df</code>의 모든 행은 유지하면서 <code>rain_df</code>에 일치하는 데이터가 있을 경우에만 병합하려고 할 때, <code>pd.merge</code> 메소드의 <code>how</code> 인자로 가장 적절한 것은 무엇입니까?</p>
  <ol>
  <li><code>inner</code></li>
  <li><code>outer</code></li>
  <li><code>left</code></li>
  <li><code>right</code></li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p>Pandas의 <code>merge</code> 메소드는 SQL의 <code>JOIN</code>과 유사하게 두 데이터프레임을 공통된 키(key)를 기준으로 결합하는 기능을 제공합니다. <code>how</code> 인자는 결합 방식을 결정하는 중요한 매개변수입니다.</p>
  <ul>
  <li><code>inner</code>: 두 데이터프레임에 모두 존재하는 키 값에 해당하는 행들만 결합합니다. (교집합)</li>
  <li><code>outer</code>: 두 데이터프레임 중 한쪽에라도 존재하는 모든 키 값에 해당하는 행들을 결합합니다. 일치하는 키가 없는 경우, 해당 값은 결측치(NaN)로 채워집니다. (합집합)</li>
  <li><code>left</code>: 왼쪽 데이터프레임(첫 번째 인자로 전달된 데이터프레임)의 모든 행을 유지하면서, 오른쪽 데이터프레임에서 일치하는 키 값의 데이터를 결합합니다. 오른쪽 데이터프레임에 일치하는 키가 없으면 결측치(NaN)로 채워집니다.</li>
  <li><code>right</code>: 오른쪽 데이터프레임의 모든 행을 유지하면서, 왼쪽 데이터프레임에서 일치하는 키 값의 데이터를 결합합니다.</li>
  </ul>
  <p>문제에서는 &#39;<code>daily_usage_df</code>의 모든 행을 유지&#39;한다고 명시했습니다. <code>pd.merge(daily_usage_df, rain_df, ...)</code>와 같이 호출할 때 <code>daily_usage_df</code>가 왼쪽 데이터프레임이 되므로, 왼쪽 데이터프레임의 모든 행을 보존하는 <code>left</code> 조인이 가장 적절합니다. 참고 자료에서도 다음과 같은 코드를 예시로 들고 있습니다.</p>
  <p><code>merged_df = pd.merge(daily_usage_df, rain_df, how=&#39;left&#39;, left_on=&#39;기준_날짜&#39;, right_on=&#39;일시&#39;)</code></p>
  <p>이 코드는 <code>daily_usage_df</code>를 기준으로 <code>rain_df</code>의 강수량 데이터를 날짜에 맞춰 결합하는 작업을 수행합니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">3. 피어슨 상관계수(Pearson Correlation Coefficient)에 대한 설명으로 올바른 것을 고르시오.</p>
  <ol>
  <li>두 변수 간의 모든 종류의 관계를 측정하는 지표이다.</li>
  <li>계수 값이 0에 가까울수록 두 변수는 강한 양의 상관관계를 가진다.</li>
  <li>-1에서 1 사이의 값을 가지며, 두 연속형 변수 간의 &#39;선형&#39; 관계를 측정한다.</li>
  <li>Pandas에서는 <code>corr()</code> 메소드를 통해 계산할 수 없으며, 별도의 통계 라이브러리가 필요하다.</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p>피어슨 상관계수는 두 연속형 변수 사이의 &#39;선형적인 관계&#39;의 강도와 방향을 측정하는 통계적 지표입니다. 참고 자료에 따르면 피어슨 상관계수의 특징은 다음과 같습니다.</p>
  <ul>
  <li><strong>측정 대상:</strong> 두 &#39;연속형 변수&#39; 간의 &#39;선형&#39; 관계를 측정합니다. 비선형적인 관계(예: U자형 관계)는 제대로 측정하지 못할 수 있습니다. (1번 설명은 &#39;모든 종류의 관계&#39;라고 하여 틀림)</li>
  <li><strong>값의 범위와 의미:</strong>
  <ul>
  <li>값은 -1에서 +1 사이의 범위를 가집니다.</li>
  <li>+1에 가까울수록 강한 양의 선형 관계 (한 변수가 증가할 때 다른 변수도 증가)를 의미합니다.</li>
  <li>-1에 가까울수록 강한 음의 선형 관계 (한 변수가 증가할 때 다른 변수는 감소)를 의미합니다.</li>
  <li>0에 가까울수록 선형적인 관계가 약하거나 없음을 의미합니다. (2번 설명은 반대로 되어 있어 틀림)</li>
  </ul>
  </li>
  <li><strong>계산 방법:</strong> Pandas DataFrame에서는 <code>corr()</code> 메소드를 사용하여 매우 쉽게 피어슨 상관계수를 계산할 수 있습니다. 이 메소드는 데이터프레임의 모든 숫자형 열 간의 상관계수 행렬을 반환합니다. (4번 설명은 틀림)</li>
  </ul>
  <p>따라서, -1에서 1 사이의 값을 가지며 두 연속형 변수 간의 선형 관계를 측정한다는 3번 설명이 가장 정확합니다. 참고 자료의 &#39;날씨와 자전거 이용량의 상관관계 분석&#39; 프로젝트에서도 이 방법을 활용하여 변수 간의 관계를 파악합니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">4. &#39;서울시 공공자전거 따릉이&#39; 데이터 분석 프로젝트에서 수행한 데이터 전처리 과정에 해당하지 <u>않는</u> 것은 무엇입니까?</p>
  <ol>
  <li>CSV 형태로 수집된 데이터의 기초 통계량 산출</li>
  <li>결측치 처리 및 이상치 제거</li>
  <li>날짜/시간 데이터의 형식 변환</li>
  <li>딥러닝 모델을 이용한 데이터 증강(Data Augmentation)</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 4번</h4>
  <p><strong>해설:</strong></p>
  <p>참고 자료의 &#39;실습 프로젝트&#39; 개요 표에 따르면, &#39;서울시 따릉이&#39; 데이터 분석 프로젝트는 다음과 같은 단계로 구성됩니다.</p>
  <table>
  <thead>
  <tr>
  <th>단계</th>
  <th>주요 내용</th>
  </tr>
  </thead>
  
  <tbody><tr>
  <td>1. 데이터 수집 및 전처리</td>
  <td>- CSV 형태의 데이터 수집<br/>- <strong>기초 통계량 산출</strong><br/>- <strong>결측치 처리 및 이상치 제거</strong><br/>- <strong>날짜 / 시간 데이터 형식 변환</strong></td>
  </tr>
  <tr>
  <td>2. 데이터 분석</td>
  <td>- 시계열 패턴 분석</td>
  </tr>
  <tr>
  <td>3. 연계 분석</td>
  <td>- 강수량 데이터와의 연계 분석<br/>- 상관관계 분석</td>
  </tr>
  
  </tbody></table>
  <p>위 표에서 볼 수 있듯이, 데이터 전처리 단계에서는 다음과 같은 작업들을 수행합니다.</p>
  <ul>
  <li><strong>기초 통계량 산출:</strong> <code>describe()</code>와 같은 함수를 사용하여 데이터의 전반적인 분포(평균, 표준편차, 최소/최대값 등)를 파악합니다. (1번 해당)</li>
  <li><strong>결측치 처리 및 이상치 제거:</strong> 데이터의 품질을 높이기 위해 비어있는 값(결측치)을 채우거나 제거하고, 일반적인 분포에서 크게 벗어나는 값(이상치)을 처리합니다. (2번 해당)</li>
  <li><strong>날짜/시간 데이터 형식 변환:</strong> 문자열(object) 형태로 저장된 날짜/시간 데이터를 <code>datetime</code> 형식으로 변환하여 시간 관련 연산(요일, 시간대 추출 등)이 가능하도록 만듭니다. (3번 해당)</li>
  </ul>
  <p>반면, &#39;딥러닝 모델을 이용한 데이터 증강&#39;은 주로 이미지나 텍스트 데이터의 양이 부족할 때, 기존 데이터를 변형하여 학습 데이터의 양을 늘리는 기법입니다. 본 정형 데이터 분석 프로젝트의 전처리 과정에서는 언급되지 않은 내용입니다. 따라서 4번이 정답입니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">5. &#39;서울 열린데이터 광장&#39;에 대한 설명으로 가장 적절한 것은 무엇입니까?</p>
  <ol>
  <li>전 세계의 모든 공공 데이터를 수집하여 제공하는 글로벌 포털이다.</li>
  <li>주로 비정형 데이터인 이미지와 영상 데이터만을 제공한다.</li>
  <li>서울특별시에서 운영하며, 교통, 환경, 복지 등 다양한 분야의 공공 데이터를 제공한다.</li>
  <li>데이터는 오직 API 형식으로만 제공되며, 파일 다운로드는 불가능하다.</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p>참고 자료 &#39;정형 데이터 분석&#39;의 &#39;데이터 수집&#39; 파트에 따르면 &#39;서울 열린데이터 광장(data.seoul.go.kr)&#39;은 다음과 같이 설명됩니다.</p>
  <ul>
  <li><strong>운영 주체 및 데이터 범위:</strong> &#39;서울특별시에서 운영하는 공공데이터 포털&#39;로, 서울시와 관련된 &#39;교통, 환경, 복지, 안전, 인구 등 다양한 분야의 데이터&#39;를 제공합니다. (3번 설명과 일치, 1번 설명은 범위가 틀림)</li>
  <li><strong>데이터 형태:</strong> 데이터를 &#39;표 형태 또는 API 형식&#39;으로 제공합니다. 이는 정형 데이터가 주를 이룬다는 것을 의미합니다. (2번 설명은 데이터 종류가 틀림)</li>
  <li><strong>다운로드 형식:</strong> &#39;CSV, JSON, XML 등 다양한 형식으로 다운로드 가능&#39;하다고 명시되어 있습니다. 따라서 API로만 제공된다는 4번 설명은 사실과 다릅니다.</li>
  </ul>
  <p>실습 프로젝트에서도 &#39;서울 열린데이터 광장&#39;에서 제공하는 &#39;따릉이&#39; 이용 데이터를 CSV 파일 형태로 다운로드하여 분석을 진행했습니다. 따라서 서울시가 운영하며 다양한 분야의 데이터를 여러 형식으로 제공한다는 3번 설명이 가장 정확합니다.</p>
  </div>
  </details>
  </div>
  <h2 class="section-title" id="section-2">II. 반정형 데이터 분석 (Semi-structured Data Analysis)</h2>
  <div class="question-block">
  <p class="question-text">6. 반정형 데이터에 대한 설명으로 가장 올바른 것은 무엇입니까?</p>
  <ol>
  <li>행과 열의 스키마가 엄격하게 정의된 데이터로, 관계형 데이터베이스에 저장된다.</li>
  <li>데이터 내에 자체적인 구조를 설명하는 메타데이터(태그 등)를 포함하고 있다.</li>
  <li>이미지, 오디오 파일과 같이 내부 구조를 파악하기 어려운 데이터의 총칭이다.</li>
  <li>분석을 위해서는 반드시 정형 데이터 형태로 변환해야만 한다.</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 2번</h4>
  <p><strong>해설:</strong></p>
  <p>반정형 데이터는 정형 데이터와 비정형 데이터의 중간적 특성을 갖는 데이터입니다. 참고 자료 &#39;반정형 데이터 분석&#39;에 따르면 다음과 같은 특징을 가집니다.</p>
  <ul>
  <li><strong>정의:</strong> &#39;완전한 정형 데이터는 아니지만 일정한 구조와 규칙을 가진 데이터 유형&#39;으로 정의됩니다. 대표적인 예로 HTML, XML, JSON이 있습니다.</li>
  <li><strong>구조적 특징:</strong> 정형 데이터처럼 고정된 스키마(Schema)를 따르지는 않지만, 데이터 내에 태그(tag)나 키-값(key-value) 쌍 등을 이용해 데이터의 구조와 의미를 설명하는 메타데이터를 포함하고 있습니다. 예를 들어, HTML의 <code>&lt;h1&gt;</code> 태그는 해당 텍스트가 최상위 제목임을 나타내고, JSON의 <code>{&#34;name&#34;: &#34;John&#34;}</code>은 &#39;name&#39;이라는 키가 &#39;John&#39;이라는 값을 가짐을 명시합니다. 이처럼 데이터가 스스로를 설명하는(self-describing) 특징이 있습니다. (2번 설명)</li>
  <li><strong>비교:</strong>
  <ul>
  <li>1번은 엄격한 스키마를 가진 &#39;정형 데이터&#39;에 대한 설명입니다.</li>
  <li>3번은 내부 구조가 없는 &#39;비정형 데이터&#39;에 대한 설명입니다.</li>
  <li>4번은 틀린 설명입니다. 반정형 데이터는 lxml, JSON 파서 등 전용 라이브러리를 통해 내재된 구조를 직접 파싱하여 필요한 정보를 추출할 수 있으며, 항상 정형 데이터로 변환해야 하는 것은 아닙니다.</li>
  </ul>
  </li>
  </ul>
  <p>따라서 데이터 내에 구조를 설명하는 메타데이터를 포함하고 있다는 2번 설명이 반정형 데이터의 핵심적인 특징을 가장 잘 나타냅니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">7. 웹 스크래핑 시 동적 웹 페이지(JavaScript에 의해 내용이 변경되는 페이지)의 데이터를 수집하기 위해 웹 브라우저 자체를 자동화하는 라이브러리는 무엇입니까?</p>
  <ol>
  <li>lxml</li>
  <li>Selenium</li>
  <li>Kiwi</li>
  <li>matplotlib</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 2번</h4>
  <p><strong>해설:</strong></p>
  <p>웹 스크래핑은 웹 페이지에서 원하는 데이터를 추출하는 기술입니다. 웹 페이지는 정적 페이지와 동적 페이지로 나눌 수 있습니다.</p>
  <ul>
  <li><strong>정적 웹 페이지:</strong> 서버로부터 받은 HTML 내용이 그대로 화면에 표시되는 페이지입니다.</li>
  <li><strong>동적 웹 페이지:</strong> 초기 HTML 로드 후, JavaScript가 실행되어 페이지의 내용이 동적으로 변경되거나 추가되는 페이지입니다. (예: &#39;더보기&#39; 버튼 클릭, 스크롤 시 추가 콘텐츠 로딩)</li>
  </ul>
  <p>참고 자료에 따르면 각 라이브러리의 역할은 다음과 같습니다.</p>
  <ul>
  <li><strong>lxml:</strong> 다운로드된 HTML이나 XML 문서를 파싱(parsing)하고, XPath 등을 이용해 원하는 데이터를 &#39;추출&#39;하는 데 특화된 라이브러리입니다. 이미 받아온 정적인 HTML 파일에서 데이터를 찾는 역할을 합니다.</li>
  <li><strong>Selenium:</strong> &#39;웹 브라우저를 자동화&#39;하여 실제 사용자가 하는 것처럼 클릭, 스크롤, 텍스트 입력 등의 행동을 코드로 제어할 수 있습니다. 이 기능을 통해 JavaScript가 모두 실행되어 최종적으로 렌더링된 상태의 HTML을 얻을 수 있으므로, &#39;동적 웹 페이지&#39;나 로그인이 필요한 페이지의 데이터 수집에 매우 효과적입니다.</li>
  <li><strong>Kiwi:</strong> 한국어 형태소 분석 라이브러리로, 텍스트 데이터 처리(자연어 처리)에 사용됩니다.</li>
  <li><strong>matplotlib:</strong> 데이터 시각화 라이브러리로, 그래프나 차트를 그리는 데 사용됩니다.</li>
  </ul>
  <p>따라서 웹 브라우저를 직접 구동하고 자동화하여 동적 콘텐츠를 가져오는 역할을 하는 라이브러리는 <strong>Selenium</strong>입니다. 실습 프로젝트에서도 Selenium으로 동적 페이지에 접근하여 HTML을 가져온 뒤, lxml로 파싱하는 방식을 사용합니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">8. lxml 라이브러리에서 XPath를 사용하여 HTML 문서를 파싱할 때, 현재 위치와 관계없이 문서 내의 모든 <code>&lt;a&gt;</code> 태그를 선택하는 문법으로 올바른 것은 무엇입니까?</p>
  <ol>
  <li><code>/a</code></li>
  <li><code>.//a</code></li>
  <li><code>a[]</code></li>
  <li><code>@a</code></li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 2번</h4>
  <p><strong>해설:</strong></p>
  <p>XPath는 XML 및 HTML 문서 내의 특정 요소(element), 속성(attribute), 텍스트 등을 선택하기 위한 경로 표현 언어입니다. 참고 자료에 제시된 주요 XPath 문법은 다음과 같습니다.</p>
  <table>
  <thead>
  <tr>
  <th>XPath 문법</th>
  <th>설명</th>
  </tr>
  </thead>
  
  <tbody><tr>
  <td><code>/</code></td>
  <td>절대 경로 : 루트 요소부터 시작</td>
  </tr>
  <tr>
  <td><code>//</code></td>
  <td>상대 경로 : 현재 위치에서 모든 하위 요소 선택</td>
  </tr>
  <tr>
  <td><code>.</code></td>
  <td>현재 노드</td>
  </tr>
  <tr>
  <td><code>@</code></td>
  <td>속성 선택</td>
  </tr>
  <tr>
  <td><code>text()</code></td>
  <td>요소의 텍스트 값 선택</td>
  </tr>
  <tr>
  <td><code>[ ]</code></td>
  <td>조건 설정</td>
  </tr>
  <tr>
  <td><code>*</code></td>
  <td>모든 요소 선택</td>
  </tr>
  
  </tbody></table>
  <p>각 보기의 의미를 분석해 보면 다음과 같습니다.</p>
  <ul>
  <li><code>/a</code>: 루트(최상위) 요소 바로 아래에 있는 <code>&lt;a&gt;</code> 태그를 선택합니다. 매우 제한적인 경우에만 해당됩니다.</li>
  <li><code>.//a</code>: <code>.</code>은 현재 노드를 의미하고, <code>//</code>는 그 아래의 모든 하위 요소를 의미합니다. 따라서 <code>.//a</code>는 &#39;현재 노드를 포함한 모든 하위 노드 중에서 <code>&lt;a&gt;</code> 태그를 선택&#39;하라는 의미입니다. 만약 문서 전체에서 찾고 싶다면 보통 <code>//a</code>라고 쓰는데, 이는 루트 노드부터 시작하여 모든 하위 요소를 검색하므로 사실상 문서 내 모든 <code>&lt;a&gt;</code> 태그를 선택하는 가장 일반적인 방법입니다. 보기 중에서는 <code>.//a</code>가 이와 가장 유사한 의미를 가집니다.</li>
  <li><code>a[]</code>: 문법적으로 올바르지 않거나, 조건이 비어있는 형태입니다. 보통 <code>a[@href]</code>와 같이 대괄호 안에는 속성이나 위치 등의 조건을 명시합니다.</li>
  <li><code>@a</code>: 이름이 &#39;a&#39;인 &#39;속성&#39;을 선택하라는 의미입니다. <code>&lt;div a=&#34;some_value&#34;&gt;</code>와 같은 경우에 사용되며, 태그를 선택하는 것이 아닙니다.</li>
  </ul>
  <p>따라서 현재 위치와 관계없이 문서 내의 모든 특정 태그를 찾을 때는 <code>//</code> 문법을 사용해야 하므로, 2번이 가장 적절한 답입니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">9. 한국어 텍스트 데이터 전처리 과정에서 &#39;하나의 단어가 다양한 어미나 조사와 결합하는 교착어의 특성&#39; 때문에 특히 중요한 분석 단계는 무엇입니까?</p>
  <ol>
  <li>정규표현식을 이용한 특수문자 제거</li>
  <li>워드 클라우드 생성</li>
  <li>형태소 분석</li>
  <li>단어 빈도 분석</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p>참고 자료 &#39;반정형 데이터 분석&#39;의 &#39;형태소 분석&#39; 파트에서는 한국어 처리의 특수성을 강조하고 있습니다.</p>
  <p>한국어는 &#39;교착어&#39;에 속합니다. 교착어는 실질적인 의미를 나타내는 어근(예: &#39;먹다&#39;의 &#39;먹-&#39;)에 문법적인 기능을 하는 접사(어미, 조사 등)가 결합하여 단어를 형성하는 언어입니다. 이로 인해 같은 의미의 단어라도 문장에서의 역할에 따라 형태가 매우 다양해집니다.</p>
  <ul>
  <li>예시: &#39;분석하다&#39;, &#39;분석하고&#39;, &#39;분석하면&#39;, &#39;분석했다&#39;, &#39;분석은&#39;, &#39;분석을&#39; ...</li>
  </ul>
  <p>이 단어들은 모두 &#39;분석&#39;이라는 핵심 의미를 공유하지만, 컴퓨터는 이들을 모두 다른 단어로 인식합니다. 이 문제를 해결하기 위해 <strong>형태소 분석</strong>이 필요합니다.</p>
  <p><strong>형태소 분석</strong>은 문장을 문법적인 의미를 가지는 최소 단위인 &#39;형태소&#39;로 분리하고, 각 형태소의 품사(명사, 동사, 조사 등)를 파악하는 과정입니다. 이를 통해 &#39;분석했다&#39;를 &#39;분석(명사) + 하(동사 어근) + 었(과거 시제 선어말 어미) + 다(종결 어미)&#39;와 같이 분리하여 &#39;분석&#39;이라는 핵심 단어를 추출(어간 추출 또는 표제어 추출)할 수 있습니다. 이렇게 해야만 단어의 진짜 빈도를 정확하게 셀 수 있습니다.</p>
  <p>다른 보기들은 다음과 같습니다.</p>
  <ul>
  <li><strong>특수문자 제거:</strong> 텍스트 정제의 일부이지만, 교착어의 특성과 직접적인 관련은 적습니다.</li>
  <li><strong>워드 클라우드 생성, 단어 빈도 분석:</strong> 형태소 분석이 선행되어야 정확한 결과를 얻을 수 있는 후속 분석 단계입니다.</li>
  </ul>
  <p>따라서 교착어인 한국어의 특성 때문에 가장 중요하게 요구되는 전처리 단계는 형태소 분석입니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">10. 대규모 언어 모델(LLM)을 활용하여 게시글을 여러 카테고리로 자동 분류하는 작업을 무엇이라고 합니까?</p>
  <ol>
  <li>텍스트 요약 (Text Summarization)</li>
  <li>텍스트 분류 (Text Classification)</li>
  <li>텍스트 생성 (Text Generation)</li>
  <li>질의응답 (Question Answering)</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 2번</h4>
  <p><strong>해설:</strong></p>
  <p>참고 자료 &#39;반정형 데이터 분석&#39;의 &#39;게시글 분류&#39; 파트에서는 대규모 언어 모델(LLM)의 활용에 대해 설명하고 있습니다.</p>
  <p><strong>텍스트 분류(Text Classification)</strong>는 &#39;문서나 문장을 미리 정의된 카테고리(범주)로 분류하는 작업&#39;을 의미합니다. 예를 들어, 뉴스 기사를 &#39;정치&#39;, &#39;경제&#39;, &#39;사회&#39;, &#39;스포츠&#39; 등으로 나누거나, 고객 리뷰를 &#39;긍정&#39;, &#39;부정&#39;, &#39;중립&#39;으로 판단하는 작업이 여기에 해당합니다. 문제에서 제시된 &#39;게시글을 여러 카테고리로 자동 분류하는 작업&#39;은 텍스트 분류의 정확한 정의입니다.</p>
  <p>대규모 언어 모델(LLM)은 방대한 텍스트 데이터로 사전 학습되어 문맥을 깊이 이해하는 능력이 뛰어나기 때문에, 별도의 복잡한 모델 훈련 없이도 몇 가지 예시(Few-shot learning)나 지시문(Prompt)만으로 높은 정확도의 텍스트 분류를 수행할 수 있습니다.</p>
  <p>다른 보기의 작업들은 다음과 같습니다.</p>
  <ul>
  <li><strong>텍스트 요약:</strong> 긴 글의 핵심 내용을 간추려 짧은 문장으로 만드는 작업입니다.</li>
  <li><strong>텍스트 생성:</strong> 특정 주제나 키워드에 맞춰 새로운 글을 창작하는 작업입니다.</li>
  <li><strong>질의응답:</strong> 주어진 질문에 대해 본문에서 답을 찾거나, 학습된 지식을 바탕으로 답변을 생성하는 작업입니다.</li>
  </ul>
  <p>따라서 주어진 문제에 가장 적합한 용어는 텍스트 분류입니다.</p>
  </div>
  </details>
  </div>
  <h2 class="section-title" id="section-3">III. 비정형 데이터 분석 (Unstructured Data Analysis)</h2>
  <div class="question-block">
  <p class="question-text">11. 다음 중 비정형 데이터의 특징으로 가장 적절한 것은 무엇입니까?</p>
  <ol>
  <li>전체 데이터에서 차지하는 비중이 낮지만 분석이 용이하다.</li>
  <li>일정한 형식이나 구조가 없이 저장된 정보로, 이미지, 텍스트 등이 해당된다.</li>
  <li>주로 관계형 데이터베이스에 테이블 형태로 저장된다.</li>
  <li>데이터 내에 태그나 키-값 쌍을 통해 구조를 설명하는 메타데이터를 포함한다.</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 2번</h4>
  <p><strong>해설:</strong></p>
  <p>참고 자료 &#39;비정형 데이터 분석&#39;의 &#39;비정형 데이터의 이해&#39; 파트에 따르면, 비정형 데이터는 다음과 같은 특징을 가집니다.</p>
  <ul>
  <li><strong>정의 및 형태:</strong> &#39;일정한 형식이나 구조가 없이 저장된 정보&#39;를 의미하며, &#39;이미지, 영상, 음성, 텍스트 등 다양한 형태로 존재&#39;합니다. (2번 설명)</li>
  <li><strong>데이터 양:</strong> &#39;정형 데이터에 비해 압도적인 데이터 양(전체 대비 70%)&#39;을 차지한다고 언급되어, 비중이 낮다는 1번 설명은 틀렸습니다.</li>
  <li><strong>분석의 어려움:</strong> 구조가 없기 때문에 &#39;전통적 분석으로는 처리 제한&#39;이 따릅니다. 분석이 용이하다는 1번 설명은 틀렸습니다.</li>
  <li><strong>저장 방식:</strong> 3번에서 설명하는 관계형 데이터베이스의 테이블 형태는 &#39;정형 데이터&#39;의 저장 방식입니다.</li>
  <li><strong>구조:</strong> 4번에서 설명하는 태그나 키-값 쌍을 통한 자체 설명 구조는 &#39;반정형 데이터&#39;(예: XML, JSON)의 특징입니다.</li>
  </ul>
  <p>비정형 데이터는 분석이 어렵지만, 소비자의 취향, 시장 트렌드 등 풍부한 정보를 내포하고 있어 기업의 의사결정에 매우 중요한 가치를 지닙니다. 따라서 일정한 구조 없이 다양한 형태로 존재하는 정보라는 2번 설명이 가장 정확합니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">12. 콘텐츠가 자주 갱신되는 사이트의 정보를 XML 포맷의 구조화된 형식으로 제공하여, 비정형 데이터를 실시간으로 수집하는 효율적인 메커니즘으로 사용될 수 있는 기술은 무엇입니까?</p>
  <ol>
  <li>HTML</li>
  <li>CSS</li>
  <li>RSS</li>
  <li>VLM</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p>문제에서 설명하는 기술은 <strong>RSS(Rich Site Summary 또는 Really Simple Syndication)</strong>입니다.</p>
  <p>참고 자료 &#39;비정형 데이터 분석&#39;의 &#39;RSS를 활용한 데이터 수집&#39; 파트에 따르면, RSS는 &#39;콘텐츠가 자주 갱신되는 사이트(뉴스, 블로그 등)의 정보를 XML 포맷으로 구조화된 형식으로 제공하는 기술&#39;입니다. 사용자는 RSS 리더기를 통해 여러 사이트의 업데이트된 콘텐츠를 한 곳에서 모아볼 수 있습니다.</p>
  <p>데이터 분석의 관점에서 RSS는 매우 유용합니다. 개별 웹사이트를 주기적으로 방문하여 스크래핑하지 않아도, RSS 피드(Feed)를 구독함으로써 새로운 콘텐츠(기사 제목, 요약, 링크 등)를 구조화된 XML 형태로 자동적이고 실시간으로 수집할 수 있습니다. 이는 비정형 데이터인 웹 콘텐츠를 효율적으로 수집하는 메커니즘을 제공합니다.</p>
  <img alt="RSS 작동 방식 다이어그램" src="https://picture-search.skywork.ai/image/doc/af9e3ac5462ccc637c87ac5256a7eede.jpg"/>
  <p>위 그림은 콘텐츠 제공자가 텍스트, 오디오, 비디오 등 다양한 콘텐츠를 RSS 피드로 발행하면, 구독자가 이를 받아보는 과정을 보여줍니다.</p>
  <p>다른 보기들은 다음과 같습니다.</p>
  <ul>
  <li><strong>HTML:</strong> 웹 페이지의 구조를 만드는 마크업 언어입니다.</li>
  <li><strong>CSS:</strong> HTML 문서의 스타일과 디자인을 담당합니다.</li>
  <li><strong>VLM (Vision Language Model):</strong> 이미지와 텍스트를 함께 이해하고 처리하는 AI 모델입니다.</li>
  </ul>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">13. VLM(시각 언어 모델)이나 LLM(대규모 언어 모델)에서 자연어 텍스트를 모델이 처리할 수 있는 숫자 ID의 시퀀스로 변환하는 컴포넌트의 역할은 무엇이며, 이 컴포넌트를 무엇이라고 부릅니까?</p>
  <ol>
  <li>프롬프트(Prompt) - 모델의 출력을 유도하는 지시문 역할</li>
  <li>토크나이저(Tokenizer) - 텍스트를 토큰으로 분할하고 수치로 변환하는 역할</li>
  <li>임베딩(Embedding) - 단어를 고차원 벡터 공간에 표현하는 역할</li>
  <li>파서(Parser) - 문장의 문법 구조를 분석하는 역할</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 2번</h4>
  <p><strong>해설:</strong></p>
  <p>AI 모델, 특히 딥러닝 기반의 언어 모델은 텍스트를 직접 이해할 수 없으며, 모든 입력을 숫자로 처리해야 합니다. 이 과정에서 핵심적인 역할을 하는 것이 <strong>토크나이저(Tokenizer)</strong>입니다.</p>
  <p>참고 자료 &#39;비정형 데이터 분석&#39;의 &#39;토크나이저&#39; 파트에 따르면, 토크나이저는 &#39;자연어와 기계어 사이의 번역기 역할&#39;을 하며, 두 가지 주요 단계를 거칩니다.</p>
  <ol>
  <li><strong>텍스트 분할 (Tokenization):</strong> 입력된 자연어 텍스트를 모델이 처리할 수 있는 작은 단위인 &#39;토큰(token)&#39;으로 분리합니다. 이 토큰은 단어(word), 서브워드(subword), 또는 문자(character) 수준일 수 있습니다.</li>
  <li><strong>수치 변환 (Numerical Conversion):</strong> 분리된 각 토큰을 모델이 미리 학습한 어휘 사전(vocabulary)을 참조하여 고유한 숫자 ID로 변환합니다. 예를 들어, &#34;I love you&#34;라는 문장은 [&#34;I&#34;, &#34;love&#34;, &#34;you&#34;]로 토큰화된 후, [25, 2201, 345]와 같은 숫자 시퀀스로 변환됩니다.</li>
  </ol>
  <p>이 과정을 통해 모델은 텍스트를 입력으로 받아 처리할 수 있게 됩니다. 아래 그림은 VLM에서 텍스트 입력이 토크나이저를 거쳐 처리되는 과정을 보여줍니다.</p>
  <img alt="VLM 아키텍처 내 토크나이저 위치" src="https://picture-search.skywork.ai/image/doc/e695277517e6ffaa2bd3f20eb2dd0117.jpg"/>
  <p>따라서 텍스트를 토큰으로 분할하고 이를 숫자 ID로 변환하는 역할을 하는 컴포넌트는 토크나이저입니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">14. AI 모델로부터 원하는 결과를 효과적으로 얻기 위해 모델에 제공하는 입력 텍스트(지시문)를 설계하는 것을 무엇이라고 합니까?</p>
  <ol>
  <li>파인튜닝 (Fine-tuning)</li>
  <li>백테스팅 (Backtesting)</li>
  <li>프롬프트 설계 (Prompt Design)</li>
  <li>데이터 정규화 (Data Normalization)</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p><strong>프롬프트(Prompt)</strong>는 AI 모델, 특히 LLM이나 VLM과 같은 생성 모델에 제공하는 입력 텍스트를 의미합니다. 이 프롬프트는 모델이 수행해야 할 작업을 명시하고, 출력의 방향과 형식을 제어하는 &#39;지시문&#39; 역할을 합니다. <strong>프롬프트 설계(Prompt Design)</strong> 또는 <strong>프롬프트 엔지니어링(Prompt Engineering)</strong>은 이러한 프롬프트를 어떻게 구성해야 모델로부터 더 정확하고 원하는 형태의 결과를 얻을 수 있는지를 연구하고 적용하는 과정입니다.</p>
  <p>참고 자료 &#39;비정형 데이터 분석&#39;의 &#39;프롬프트의 개념과 설계&#39; 파트에서는 효과적인 프롬프트 설계를 위한 몇 가지 원칙을 제시합니다.</p>
  <ul>
  <li>명확하고 구체적인 지시 포함</li>
  <li>원하는 출력 형식과 스타일 명시</li>
  <li>필요시 예시 제공 (Few-shot Prompting)</li>
  <li>맥락 정보와 배경 지식 추가</li>
  <li>복잡한 작업을 단계별로 분해하여 안내</li>
  </ul>
  <p>다른 보기들은 다음과 같은 의미를 가집니다.</p>
  <ul>
  <li><strong>파인튜닝:</strong> 사전 학습된 모델을 특정 도메인이나 작업에 맞게 추가적으로 학습시키는 과정입니다.</li>
  <li><strong>백테스팅:</strong> 투자 전략 등을 과거 데이터에 적용하여 성과를 검증하는 과정입니다.</li>
  <li><strong>데이터 정규화:</strong> 데이터의 범위를 일정하게(예: 0과 1 사이) 조정하는 데이터 전처리 기법입니다.</li>
  </ul>
  <p>따라서 모델에 제공하는 입력 지시문을 설계하는 행위는 프롬프트 설계에 해당합니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">15. 비정형 데이터 분석 실습 프로젝트(패션 트렌드 분석)에서 VLM(시각 언어 모델)이 수행한 핵심적인 역할은 무엇입니까?</p>
  <ol>
  <li>RSS 피드에서 이미지 URL을 자동으로 수집하는 역할</li>
  <li>수집된 이미지의 해상도를 높이는 역할</li>
  <li>이미지를 보고 옷의 스타일, 색상, 트렌드 특징 등을 자연어로 설명하는 역할</li>
  <li>자연어 설명문에서 키워드를 추출하고 워드 클라우드를 생성하는 역할</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p>참고 자료 &#39;비정형 데이터 분석&#39;의 실습 프로젝트 개요와 정리하기 파트를 종합해 보면, 각 기술의 역할은 다음과 같이 분담됩니다.</p>
  <p><strong>VLM(Vision Language Model)</strong>은 &#39;이미지를 이해하고 이를 자연어로 설명하는 AI 모델&#39;입니다. 실습 프로젝트에서는 이 능력을 활용하여 다음과 같은 핵심적인 역할을 수행했습니다.</p>
  <ul>
  <li><strong>이미지 필터링:</strong> 프롬프트를 이용해 사람의 전신이 나온 사진 등 분석에 적합한 이미지만을 선별합니다.</li>
  <li><strong>스타일 분석:</strong> 필터링된 이미지를 입력으로 받아, 프롬프트의 지시에 따라 &#34;사람이 입은 옷의 스타일을 설명해 줘&#34;와 같은 요청을 수행합니다. 즉, 이미지 속 패션 아이템의 스타일, 색상, 소재, 트렌드 특징 등을 상세한 자연어 텍스트로 변환(설명)하는 역할을 합니다. (3번 설명)</li>
  </ul>
  <p>이처럼 VLM은 시각 정보(이미지)를 풍부한 텍스트 정보로 전환하여 정성적인 인사이트를 제공하는 다리 역할을 합니다.</p>
  <p>다른 보기의 역할은 다음과 같습니다.</p>
  <ul>
  <li>1번(이미지 URL 수집): <code>requests</code>와 <code>lxml</code> 라이브러리를 이용한 웹 스크래핑 단계에서 수행됩니다.</li>
  <li>2번(해상도 개선): 프로젝트 내용에 포함되지 않은 기능입니다.</li>
  <li>4번(키워드 추출 및 시각화): VLM이 생성한 텍스트 설명을 바탕으로, <strong>LLM(대규모 언어 모델)</strong>을 활용하여 키워드를 추출하고, 추출된 키워드의 빈도를 분석하여 워드 클라우드를 생성하는 후속 단계에서 수행됩니다.</li>
  </ul>
  </div>
  </details>
  </div>
  <h2 class="section-title" id="section-4">IV. 시계열 데이터 분석 (Time-Series Data Analysis)</h2>
  <div class="question-block">
  <p class="question-text">16. 시계열 데이터가 일반 데이터와 구별되는 가장 큰 차이점은 무엇입니까?</p>
  <ol>
  <li>데이터의 양이 항상 매우 많다.</li>
  <li>관측치들 간에 시간적 순서와 의존성이 존재한다.</li>
  <li>숫자형 데이터로만 구성되어 있다.</li>
  <li>데이터 수집 주기가 항상 일정하지 않다.</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 2번</h4>
  <p><strong>해설:</strong></p>
  <p>시계열 데이터는 &#39;시간의 흐름에 따라 순차적으로 기록된 값들의 집합&#39;입니다. 참고 자료 &#39;시계열 데이터 분석&#39;에 따르면, 시계열 데이터가 일반 데이터(예: 설문조사 결과와 같은 횡단면 데이터)와 구별되는 가장 근본적인 특징은 <strong>&#39;관측치 간의 시간적 의존성&#39;</strong>입니다.</p>
  <ul>
  <li><strong>시간적 의존성:</strong> 시계열 데이터의 현재 값은 과거의 값에 영향을 받고, 또한 미래의 값에 영향을 줍니다. 예를 들어, 오늘의 주가는 어제의 주가와 밀접한 관련이 있습니다. 이러한 데이터 포인트 간의 순서와 상호 의존성 때문에 일반적인 통계 분석 방법을 그대로 적용하기 어려우며, 시계열 데이터에 특화된 분석 방법론이 필요합니다. (2번 설명)</li>
  </ul>
  <p>다른 보기들이 틀린 이유는 다음과 같습니다.</p>
  <ul>
  <li>1번: 시계열 데이터는 양이 많은 경우가 흔하지만, 이것이 본질적인 정의는 아닙니다. 짧은 기간의 시계열 데이터도 존재합니다.</li>
  <li>3번: 시계열 데이터는 주로 숫자형이지만, 범주형 시계열 데이터도 존재할 수 있습니다.</li>
  <li>4번: 시계열 분석은 &#39;일정한 시간 간격&#39;으로 수집된 데이터를 가정하는 경우가 많습니다. 수집 주기가 불규칙한 경우도 있지만, 이것이 시계열 데이터의 특징이라기보다는 처리해야 할 문제점에 가깝습니다.</li>
  </ul>
  <p>따라서 데이터 포인트들이 시간 순서를 가지며 서로에게 영향을 미친다는 &#39;시간적 의존성&#39;이 시계열 데이터를 정의하는 가장 핵심적인 차이점입니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">17. 시계열 데이터를 구성하는 4가지 요소 중, 1년 또는 1주일과 같이 고정된 시간 주기로 반복되는 패턴을 의미하는 것은 무엇입니까?</p>
  <ol>
  <li>추세 (Trend)</li>
  <li>계절성 (Seasonality)</li>
  <li>주기성 (Cyclicality)</li>
  <li>불규칙성 (Irregularity)</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 2번</h4>
  <p><strong>해설:</strong></p>
  <p>시계열 데이터는 일반적으로 다음과 같은 4가지 구성 요소의 결합으로 표현될 수 있습니다.</p>
  <ul>
  <li><strong>추세 (Trend):</strong> 데이터가 장기적으로 상승하거나 하락하는 전반적인 방향성을 의미합니다. 시계열의 기본 골격을 형성합니다. (예: 수십 년에 걸친 국가 인구 증가)</li>
  <li><strong>계절성 (Seasonality):</strong> &#39;일정한 시간 주기&#39;로 반복되는 패턴을 의미합니다. 이 주기는 &#39;일별, 주간, 월간, 연간 등 고정된 주기&#39;로 나타나는 변동입니다. (예: 여름철 아이스크림 판매량 증가, 월말의 카드 사용량 급증) (2번 설명)</li>
  <li><strong>주기성 (Cyclicality):</strong> 계절성보다 &#39;긴 기간&#39;에 걸쳐 나타나는, 주기가 고정되지 않은 상승과 하강의 반복 패턴입니다. 주로 경기 변동과 같이 수 년에 걸쳐 나타나는 사이클을 의미합니다. (예: 5~10년 주기의 비즈니스 사이클)</li>
  <li><strong>불규칙성 (Irregularity):</strong> 위의 세 가지 요소로 설명할 수 없는, 예측 불가능한 무작위적 변동(노이즈)을 의미합니다. (예: 갑작스러운 자연재해로 인한 생산량 감소)</li>
  </ul>
  <p>문제에서 &#39;1년 또는 1주일과 같이 고정된 시간 주기&#39;를 명시했으므로, 이는 계절성(Seasonality)의 정확한 정의에 해당합니다.</p>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">18. 주가 데이터 분석에서 사용되는 기술적 지표인 상대강도지수(RSI)에 대한 설명으로 올바른 것은 무엇입니까?</p>
  <ol>
  <li>주가의 장기적인 상승 또는 하락 추세를 파악하는 지표이다.</li>
  <li>일정 기간 동안의 가격 평균을 계산하여 단기 변동성을 완화하는 지표이다.</li>
  <li>상승폭과 하락폭의 상대적 강도를 측정하며, 과매수/과매도 상태를 판단하는 데 사용된다.</li>
  <li>50일 이동평균선이 200일 이동평균선을 상향 돌파하는 현상을 의미한다.</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p><strong>상대강도지수(RSI, Relative Strength Index)</strong>는 주가의 &#39;모멘텀(운동량)&#39;을 측정하는 대표적인 기술적 지표 중 하나입니다. 참고 자료에 따르면 RSI는 다음과 같이 정의됩니다.</p>
  <ul>
  <li><strong>정의:</strong> &#39;특정 기간 동안의 상승폭과 하락폭의 상대적 강도를 측정하는 모멘텀 오실레이터&#39;입니다. 즉, 주가가 오르는 힘이 강한지, 내리는 힘이 강한지를 나타내는 지표입니다. (3번 설명)</li>
  <li><strong>활용:</strong> RSI 값은 보통 0과 100 사이에서 움직입니다.
                              <ul>
  <li>일반적으로 RSI가 <strong>70 이상</strong>일 경우, 주가가 단기간에 너무 많이 올라 추가 상승 여력이 적다고 판단하는 <strong>&#39;과매수(Overbought)&#39;</strong> 상태로 해석합니다.</li>
  <li>반대로 RSI가 <strong>30 이하</strong>일 경우, 주가가 너무 많이 떨어져 반등할 가능성이 있다고 보는 <strong>&#39;과매도(Oversold)&#39;</strong> 상태로 해석합니다.</li>
  </ul>
  </li>
  </ul>
  <img alt="RSI 과매수/과매도 구간" src="https://picture-search.skywork.ai/image/doc/eb14434facb85a4db8661d8d9a1d0d46.jpg"/>
  <p>위 그림은 RSI가 70 이상인 과매수 구간과 30 이하인 과매도 구간을 시각적으로 보여줍니다.</p>
  <p>다른 보기들은 다음과 같은 지표를 설명합니다.</p>
  <ul>
  <li>1번: 이는 &#39;추세(Trend)&#39;에 대한 설명에 가깝습니다.</li>
  <li>2번: 이는 &#39;이동평균(Moving Average, MA)&#39;에 대한 설명입니다.</li>
  <li>4번: 이는 단기 이동평균선이 장기 이동평균선을 돌파하는 &#39;골든크로스(Golden Cross)&#39;에 대한 설명으로, 매수 신호로 해석됩니다.</li>
  </ul>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">19. 과거 데이터를 사용하여 투자 전략의 수익성과 위험을 평가하고 효과성을 검증하는 과정을 무엇이라고 합니까?</p>
  <ol>
  <li>데이터 스누핑 (Data Snooping)</li>
  <li>백테스팅 (Backtesting)</li>
  <li>포워드 테스팅 (Forward Testing)</li>
  <li>앙상블 (Ensemble)</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 2번</h4>
  <p><strong>해설:</strong></p>
  <p><strong>백테스팅(Backtesting)</strong>은 개발한 투자 전략(예: 골든크로스 시 매수, 데드크로스 시 매도)이 과거의 시장 데이터에서도 실제로 유효했는지를 시뮬레이션하여 검증하는 과정입니다. 참고 자료 &#39;시계열 데이터 분석&#39;의 &#39;백테스팅&#39; 파트에서는 이를 &#39;과거 데이터를 통해 투자 전략의 효과성을 검증하는 과정&#39;으로 정의하고 있습니다.</p>
  <p>백테스팅을 통해 투자자는 자신의 전략이 실제 시장에 적용되기 전에 다음과 같은 사항들을 미리 평가해볼 수 있습니다.</p>
  <ul>
  <li>예상 수익률</li>
  <li>최대 손실폭 (Maximum Drawdown, MDD)</li>
  <li>승률</li>
  <li>위험 대비 수익률 (샤프 지수 등)</li>
  </ul>
  <p>다만, 백테스팅에는 한계점도 존재합니다. &#39;과거의 성과가 미래의 성과를 보장하지 않는다&#39;는 점과, 동일한 데이터로 여러 전략을 반복 테스트하다 보면 우연히 좋은 결과를 내는 전략을 선택하게 될 위험인 &#39;데이터 스누핑 편향(Data Snooping Bias)&#39;을 항상 고려해야 합니다.</p>
  <p>다른 보기들의 의미는 다음과 같습니다.</p>
  <ul>
  <li><strong>데이터 스누핑:</strong> 백테스팅 과정에서 발생할 수 있는 통계적 편향의 한 종류입니다.</li>
  <li><strong>포워드 테스팅:</strong> 백테스팅 이후, 실제 시장과 유사한 모의 투자 환경에서 전략을 검증하는 과정입니다.</li>
  <li><strong>앙상블:</strong> 여러 개의 약한 예측 모델을 결합하여 더 강한 예측 모델을 만드는 머신러닝 기법입니다.</li>
  </ul>
  </div>
  </details>
  </div>
  <div class="question-block">
  <p class="question-text">20. Meta(구 Facebook)에서 개발한 시계열 예측 라이브러리로, 추세, 계절성, 휴일 효과를 자동으로 포착하여 비전문가도 쉽게 사용할 수 있도록 설계된 프레임워크는 무엇입니까?</p>
  <ol>
  <li>GBRT (Gradient Boosting Regression Trees)</li>
  <li>Selenium</li>
  <li>Prophet</li>
  <li>yfinance</li>
  </ol>
  <details>
  <summary>정답 및 해설 보기</summary>
  <div class="explanation">
  <h4>정답: 3번</h4>
  <p><strong>해설:</strong></p>
  <p><strong>Prophet</strong>은 Meta(구 Facebook)의 Core Data Science 팀에서 개발한 시계열 데이터 예측 라이브러리입니다.</p>
  <p>참고 자료 &#39;시계열 데이터 분석&#39;의 &#39;Meta Prophet&#39; 파트에 따르면, Prophet은 다음과 같은 특징을 가집니다.</p>
  <ul>
  <li><strong>자동화된 특징 포착:</strong> 시계열 데이터의 핵심 요소인 &#39;추세(trend), 계절성(seasonality), 휴일 효과(holiday effects)&#39;를 자동으로 분해하고 모델링합니다.</li>
  <li><strong>사용 용이성:</strong> 전통적인 시계열 모델(ARIMA 등)에 비해 파라미터 튜닝이 비교적 간단하고 직관적이어서, 시계열 분석 전문가가 아니더라도 쉽게 사용할 수 있도록 설계되었습니다.</li>
  <li><strong>강건성(Robustness):</strong> 데이터의 결측값, 추세의 변화 지점(changepoints), 특이점(outliers) 등에 강건한(잘 대응하는) 특성을 가지고 있습니다.</li>
  <li><strong>베이지안 접근법:</strong> 베이지안 통계 기법을 활용하여 각 구성요소를 추정하고, 예측 결과에 대한 불확실성 구간(uncertainty intervals)을 함께 제공하여 예측의 신뢰도를 파악하기 용이합니다.</li>
  </ul>
  <p>다른 보기들은 다음과 같습니다.</p>
  <ul>
  <li><strong>GBRT:</strong> 여러 개의 약한 예측 모델(주로 의사결정 트리)을 결합하여 이전 모델의 오차를 보완해나가는 방식으로 강력한 예측 모델을 만드는 앙상블 기법입니다.</li>
  <li><strong>Selenium:</strong> 웹 브라우저 자동화 도구입니다.</li>
  <li><strong>yfinance:</strong> 야후 파이낸스(Yahoo Finance)에서 주가 데이터를 쉽게 가져올 수 있도록 하는 파이썬 라이브러리입니다.</li>
  </ul>
  <p>따라서 문제에서 설명하는 자동화된 시계열 예측 프레임워크는 Prophet입니다.</p>
  </div>
  </details>
  </div>
  </div>
  
  </body></html>